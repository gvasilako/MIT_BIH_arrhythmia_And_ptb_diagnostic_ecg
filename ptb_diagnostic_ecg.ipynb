{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ptb_diagnostic_ecg.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "NgocFjzzUrhj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ECG Heartbeat Classification from PTB data"
      ]
    },
    {
      "metadata": {
        "id": "bytoq041V3uC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ]
    },
    {
      "metadata": {
        "id": "ove-eMr-VG9o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import libraries and data"
      ]
    },
    {
      "metadata": {
        "id": "FhK9Ll9ulh-d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Baseline imported from https://github.com/CVxTz/ECG_Heartbeat_Classification/blob/master/code/baseline_ptbdb.py?fbclid=IwAR3tPR3HHMsnVo1t90CvaAgTfMFVbo-RDsBJKO1N51Xa_UVXcBLsT7cX_5g\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import collections\n",
        "\n",
        "from keras import optimizers, losses, activations, models\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
        "from keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n",
        "    concatenate, Masking, SimpleRNN, GRU, LSTM, Bidirectional, Add\n",
        "from keras.utils import plot_model\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, auc, precision_recall_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n9uvrr4Amrh0",
        "colab_type": "code",
        "outputId": "43ff5411-d51a-4253-a99c-a85b86724ffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "# Mount google drive to read data thats saved there\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ekHaAR08oAiA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_1 = pd.read_csv(\"/content/drive/My Drive/MTEC Master/Semester 2/ml4h_project3/ptbdb_normal.csv\", header=None)\n",
        "df_2 = pd.read_csv(\"/content/drive/My Drive/MTEC Master/Semester 2/ml4h_project3/ptbdb_abnormal.csv\", header=None)\n",
        "df = pd.concat([df_1, df_2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v-xmCtTgVQQS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Illustrate data"
      ]
    },
    {
      "metadata": {
        "id": "FOy2iVChZHJR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate some simple data statistics and plot them as well as possible"
      ]
    },
    {
      "metadata": {
        "id": "vPZBHf3I9a84",
        "colab_type": "code",
        "outputId": "fbfd0b73-f493-456d-df4c-10edfa71b4f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"We have a total of {} data samples, corresponding to {} points in time.\".format(df.shape[0], df.shape[1]-1))\n",
        "freq_normal = (df_1.shape[0]/df.shape[0])*100\n",
        "print(\"We have {} NORMAL data points, therefore {:.2f}% of the data.\".format(df_1.shape[0], freq_normal))\n",
        "freq_abnormal = (df_2.shape[0]/df.shape[0])*100\n",
        "print(\"We have {} ABNORMAL data points, therefore {:.2f}% of the data.\\n\".format(df_2.shape[0], freq_abnormal))\n",
        "frequencies = [freq_abnormal, freq_normal]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,5))\n",
        "df.iloc[:,187].value_counts().plot(ax=ax, kind='bar')\n",
        "ax.set_xticklabels(['Abnormal', 'Normal'])\n",
        "for line in range(2):\n",
        "     ax.text(line-0.05, frequencies[line]+700,s=str(round(frequencies[line],2))+\"%\", horizontalalignment='left', size='medium', color='black', weight='semibold')\n",
        "ax.set_title(\"Frequency of PTB\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have a total of 14552 data samples with a maximum time length of 52sec, corresponding to 187 points in time.\n",
            "We have 4046 NORMAL data points, therefore 27.80% of the data.\n",
            "We have 10506 ABNORMAL data points, therefore 72.20% of the data.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Frequency of PTB')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtUAAAFlCAYAAAAkkRSDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "6wQ9adDvMGpb",
        "colab_type": "code",
        "outputId": "8f54f924-265b-43e3-8c43-ad08e86676a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Visual plot of how normal heartbeat looks like and how an irregular heartbeat looks like.\")\n",
        "print(df_1.shape)\n",
        "df_1.iloc[0,:80]\n",
        "x_length = 135\n",
        "x=np.arange(187)/1000\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(x[:x_length],df_1.iloc[1,:x_length].ravel(),label='Normal')\n",
        "plt.plot(x[:x_length],df_2.iloc[6,:x_length].ravel(),label='Abnormal')\n",
        "plt.legend()\n",
        "plt.xlabel('Time(sec)')\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.title(\"ECG Signal\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Visual plot of how normal heartbeat looks like and how an irregular heartbeat looks like.\n",
            "(4046, 188)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABC8AAAFgCAYAAACbh1MjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIiIiKQ0JS9EREREREREJKX9f/ay0nVo9/q6AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "T32Y7gPXZkQn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Split data"
      ]
    },
    {
      "metadata": {
        "id": "kZyBeOusl16g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train, df_test = train_test_split(df, test_size=0.2, random_state=1337, stratify=df[187])\n",
        "\n",
        "\n",
        "Y = np.array(df_train[187].values).astype(np.int8)\n",
        "X = np.array(df_train[list(range(187))].values)[..., np.newaxis]\n",
        "\n",
        "Y_test = np.array(df_test[187].values).astype(np.int8)\n",
        "X_test = np.array(df_test[list(range(187))].values)[..., np.newaxis]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R4yoLm15VxuS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Implementations"
      ]
    },
    {
      "metadata": {
        "id": "U696v2FvRn2z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For computational reasons we decided to only train the models for the PTBDB dataset for 10 epochs. For the MIT dataset and Transfer learning tasks we learned for the full 100 epochs.\n",
        "\n",
        "If you want to use 100 epochs please change the variable below."
      ]
    },
    {
      "metadata": {
        "id": "U1n_JbIsk-z7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jYX8r97aVbPh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Baseline model implementation"
      ]
    },
    {
      "metadata": {
        "id": "MHZgSYxmZv6j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Code directly obtained from https://github.com/CVxTz/ECG_Heartbeat_Classification/blob/master/code/baseline_ptbdb.py"
      ]
    },
    {
      "metadata": {
        "id": "V8jHmyO62uwS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_baseline_model():\n",
        "    nclass = 1\n",
        "    inp = Input(shape=(187, 1))\n",
        "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(inp)\n",
        "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
        "    img_1 = Dropout(rate=0.1)(img_1)\n",
        "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
        "    img_1 = Dropout(rate=0.1)(img_1)\n",
        "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
        "    img_1 = Dropout(rate=0.1)(img_1)\n",
        "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = GlobalMaxPool1D()(img_1)\n",
        "    img_1 = Dropout(rate=0.2)(img_1)\n",
        "\n",
        "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
        "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
        "    dense_1 = Dense(nclass, activation=activations.sigmoid, name=\"dense_3_ptbdb\")(dense_1)\n",
        "\n",
        "    model = models.Model(inputs=inp, outputs=dense_1)\n",
        "    opt = optimizers.Adam(0.001)\n",
        "\n",
        "    model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['acc'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M-wmhDMUZ65U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Add AUROC and AUPRC score to evaluate all models"
      ]
    },
    {
      "metadata": {
        "id": "dMlPdQanOzfU",
        "colab_type": "code",
        "outputId": "0b8bf99c-4894-41f5-874b-be0543c336a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1822
        }
      },
      "cell_type": "code",
      "source": [
        "model_baseline = get_baseline_model()\n",
        "file_path = \"baseline_ptbdb.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
        "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint, early, redonplat]  # early\n",
        "\n",
        "model_baseline.fit(X, Y, epochs=n_epochs, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
        "model_baseline.load_weights(file_path)\n",
        "\n",
        "pred_test = model_baseline.predict(X_test)\n",
        "pred_test = (pred_test>0.5).astype(np.int8)\n",
        "\n",
        "print('Baseline model results')\n",
        "f1 = f1_score(Y_test, pred_test)\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "acc = accuracy_score(Y_test, pred_test)\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "\n",
        "# calculate Receiver Operating Characteristics AUC\n",
        "roc_auc = roc_auc_score(Y_test, pred_test)\n",
        "print(\"AUROC score : %s \"% roc_auc)\n",
        "\n",
        "# calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(Y_test, pred_test)\n",
        "# calculate precision-recall AUC\n",
        "prc_auc = auc(recall, precision)\n",
        "print(\"AUPRC score : %s \"% prc_auc)\n",
        "\n",
        "baseline_results = [f1, acc, roc_auc, prc_auc]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 183, 16)           96        \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 179, 16)           1296      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 89, 16)            0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 89, 16)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 87, 32)            1568      \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 85, 32)            3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 42, 32)            0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 42, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 40, 32)            3104      \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 38, 32)            3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 19, 32)            0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 19, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 17, 256)           24832     \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 15, 256)           196864    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_3_ptbdb (Dense)        (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 254,641\n",
            "Trainable params: 254,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 10476 samples, validate on 1165 samples\n",
            "Epoch 1/10\n",
            " - 18s - loss: 0.5307 - acc: 0.7286 - val_loss: 0.4570 - val_acc: 0.7708\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.77082, saving model to baseline_ptbdb.h5\n",
            "Epoch 2/10\n",
            " - 17s - loss: 0.4081 - acc: 0.8134 - val_loss: 0.3489 - val_acc: 0.8506\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.77082 to 0.85064, saving model to baseline_ptbdb.h5\n",
            "Epoch 3/10\n",
            " - 17s - loss: 0.3016 - acc: 0.8809 - val_loss: 0.2594 - val_acc: 0.9064\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.85064 to 0.90644, saving model to baseline_ptbdb.h5\n",
            "Epoch 4/10\n",
            " - 17s - loss: 0.2399 - acc: 0.9099 - val_loss: 0.1859 - val_acc: 0.9408\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.90644 to 0.94077, saving model to baseline_ptbdb.h5\n",
            "Epoch 5/10\n",
            " - 17s - loss: 0.2071 - acc: 0.9213 - val_loss: 0.1555 - val_acc: 0.9416\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.94077 to 0.94163, saving model to baseline_ptbdb.h5\n",
            "Epoch 6/10\n",
            " - 17s - loss: 0.1760 - acc: 0.9340 - val_loss: 0.1259 - val_acc: 0.9536\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.94163 to 0.95365, saving model to baseline_ptbdb.h5\n",
            "Epoch 7/10\n",
            " - 17s - loss: 0.1646 - acc: 0.9403 - val_loss: 0.1852 - val_acc: 0.9305\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.95365\n",
            "Epoch 8/10\n",
            " - 17s - loss: 0.1458 - acc: 0.9464 - val_loss: 0.1005 - val_acc: 0.9734\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.95365 to 0.97339, saving model to baseline_ptbdb.h5\n",
            "Epoch 9/10\n",
            " - 17s - loss: 0.1352 - acc: 0.9514 - val_loss: 0.1052 - val_acc: 0.9648\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.97339\n",
            "Epoch 10/10\n",
            " - 17s - loss: 0.1245 - acc: 0.9547 - val_loss: 0.1055 - val_acc: 0.9614\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.97339\n",
            "Baseline model results\n",
            "Test f1 score : 0.976897689768977 \n",
            "Test accuracy score : 0.9663345929233941 \n",
            "AUROC score : 0.9508367450388647 \n",
            "AUPRC score : 0.9821289570684167 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eEGYLTGPVrEB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Simple RNN implementation"
      ]
    },
    {
      "metadata": {
        "id": "mkHgqrZO_sLO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_simple_rnn_model(dropout=True):\n",
        "    nclass = 1\n",
        "    inp = Input(shape=(187, 1))\n",
        "    mask_inp = Masking(mask_value=0.)(inp)\n",
        "    img_1 = SimpleRNN(64)(mask_inp)\n",
        "    if(dropout):\n",
        "      img_1 = Dropout(rate=0.2)(img_1)\n",
        "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
        "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
        "    dense_1 = Dense(nclass, activation=activations.sigmoid, name=\"dense_3_ptbdb\")(dense_1)\n",
        "\n",
        "    model = models.Model(inputs=inp, outputs=dense_1)\n",
        "    opt = optimizers.Adam(0.001)\n",
        "\n",
        "    model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['acc'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BUV_xZaCdJPi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Test simple RNN model and try once with and without drop out layer"
      ]
    },
    {
      "metadata": {
        "id": "DWzegpetdGmX",
        "colab_type": "code",
        "outputId": "e34d53fb-7c36-4936-be3f-8c03747dbd57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        }
      },
      "cell_type": "code",
      "source": [
        "model = get_simple_rnn_model(dropout=False)\n",
        "file_path = \"simple_rnn_ptbdb.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
        "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint, early, redonplat]  # early\n",
        "\n",
        "model.fit(X, Y, epochs=n_epochs, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
        "model.load_weights(file_path)\n",
        "\n",
        "pred_test = model.predict(X_test)\n",
        "pred_test = (pred_test>0.5).astype(np.int8)\n",
        "\n",
        "print('Simple RNN model results')\n",
        "f1 = f1_score(Y_test, pred_test)\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "acc = accuracy_score(Y_test, pred_test)\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "\n",
        "# calculate Receiver Operating Characteristics AUC\n",
        "roc_auc = roc_auc_score(Y_test, pred_test)\n",
        "print(\"AUROC score : %s \"% roc_auc)\n",
        "\n",
        "# calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(Y_test, pred_test)\n",
        "# calculate precision-recall AUC\n",
        "prc_auc = auc(recall, precision)\n",
        "print(\"AUPRC score : %s \"% prc_auc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "masking_1 (Masking)          (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 64)                4224      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_3_ptbdb (Dense)        (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 12,609\n",
            "Trainable params: 12,609\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 10476 samples, validate on 1165 samples\n",
            "Epoch 1/10\n",
            " - 17s - loss: 0.5874 - acc: 0.7244 - val_loss: 0.6072 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to simple_rnn_ptbdb.h5\n",
            "Epoch 2/10\n",
            " - 16s - loss: 0.5851 - acc: 0.7244 - val_loss: 0.6160 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.69957\n",
            "Epoch 3/10\n",
            " - 16s - loss: 0.5862 - acc: 0.7244 - val_loss: 0.6090 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.69957\n",
            "Epoch 4/10\n",
            " - 16s - loss: 0.5929 - acc: 0.7237 - val_loss: 0.6107 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.69957\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 5/10\n",
            " - 16s - loss: 0.5865 - acc: 0.7244 - val_loss: 0.6106 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.69957\n",
            "Epoch 6/10\n",
            " - 16s - loss: 0.5872 - acc: 0.7244 - val_loss: 0.6107 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.69957\n",
            "Epoch 00006: early stopping\n",
            "Simple RNN model results\n",
            "Test f1 score : 0.8386195890684222 \n",
            "Test accuracy score : 0.7220886293369976 \n",
            "AUROC score : 0.5 \n",
            "AUPRC score : 0.8610443146684987 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aEXJN-pSO5Rv",
        "colab_type": "code",
        "outputId": "191b9e13-89c7-4c09-cfe1-204ba8b6419c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1006
        }
      },
      "cell_type": "code",
      "source": [
        "model = get_simple_rnn_model(dropout=True)\n",
        "file_path = \"simple_rnn_ptbdb.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
        "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint, early, redonplat]  # early\n",
        "\n",
        "model.fit(X, Y, epochs=n_epochs, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
        "model.load_weights(file_path)\n",
        "\n",
        "pred_test = model.predict(X_test)\n",
        "pred_test = (pred_test>0.5).astype(np.int8)\n",
        "\n",
        "print('Simple RNN model results')\n",
        "f1 = f1_score(Y_test, pred_test)\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "acc = accuracy_score(Y_test, pred_test)\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "\n",
        "# calculate Receiver Operating Characteristics AUC\n",
        "roc_auc = roc_auc_score(Y_test, pred_test)\n",
        "print(\"AUROC score : %s \"% roc_auc)\n",
        "\n",
        "# calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(Y_test, pred_test)\n",
        "# calculate precision-recall AUC\n",
        "prc_auc = auc(recall, precision)\n",
        "print(\"AUPRC score : %s \"% prc_auc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "masking_2 (Masking)          (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_2 (SimpleRNN)     (None, 64)                4224      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_3_ptbdb (Dense)        (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 12,609\n",
            "Trainable params: 12,609\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10476 samples, validate on 1165 samples\n",
            "Epoch 1/10\n",
            " - 17s - loss: 0.5933 - acc: 0.7241 - val_loss: 0.6107 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to simple_rnn_ptbdb.h5\n",
            "Epoch 2/10\n",
            " - 16s - loss: 0.5887 - acc: 0.7244 - val_loss: 0.6055 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.69957\n",
            "Epoch 3/10\n",
            " - 16s - loss: 0.5882 - acc: 0.7242 - val_loss: 0.6142 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.69957\n",
            "Epoch 4/10\n",
            " - 16s - loss: 0.5937 - acc: 0.7244 - val_loss: 0.6143 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.69957\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 5/10\n",
            " - 16s - loss: 0.5892 - acc: 0.7244 - val_loss: 0.6125 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.69957\n",
            "Epoch 6/10\n",
            " - 17s - loss: 0.5899 - acc: 0.7244 - val_loss: 0.6109 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.69957\n",
            "Epoch 00006: early stopping\n",
            "Simple RNN model results\n",
            "Test f1 score : 0.8386195890684222 \n",
            "Test accuracy score : 0.7220886293369976 \n",
            "AUROC score : 0.5 \n",
            "AUPRC score : 0.8610443146684987 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gFZwvXFpdSBE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Drop out improves model considerably. For all future implementations we will therefore use dropout."
      ]
    },
    {
      "metadata": {
        "id": "VwI4xogCV97g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GRU implementation\n",
        "\n",
        "> Test different hidden layer size\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "DUMxVR5tDVei",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_gru_model(n_hidden=64):\n",
        "    nclass = 1\n",
        "    inp = Input(shape=(187, 1))\n",
        "    mask_inp = Masking(mask_value=0.)(inp)\n",
        "    img_1 = GRU(n_hidden)(mask_inp)\n",
        "    img_1 = Dropout(rate=0.2)(img_1)\n",
        "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
        "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
        "    dense_1 = Dense(nclass, activation=activations.sigmoid, name=\"dense_3_ptbdb\")(dense_1)\n",
        "\n",
        "    model = models.Model(inputs=inp, outputs=dense_1)\n",
        "    opt = optimizers.Adam(0.001)\n",
        "\n",
        "    model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['acc'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3ZcrT7E0Ph4s",
        "colab_type": "code",
        "outputId": "4bddc561-482e-476f-a668-13018a52d704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1156
        }
      },
      "cell_type": "code",
      "source": [
        "model = get_gru_model(n_hidden=64)\n",
        "file_path = \"gru_64_ptbdb.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
        "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint, early, redonplat]  # early\n",
        "\n",
        "model.fit(X, Y, epochs=n_epochs, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
        "model.load_weights(file_path)\n",
        "\n",
        "pred_test = model.predict(X_test)\n",
        "pred_test = (pred_test>0.5).astype(np.int8)\n",
        "\n",
        "print('GRU with 64 hidden layers model results')\n",
        "f1 = f1_score(Y_test, pred_test)\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "acc = accuracy_score(Y_test, pred_test)\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "\n",
        "# calculate Receiver Operating Characteristics AUC\n",
        "roc_auc = roc_auc_score(Y_test, pred_test)\n",
        "print(\"AUROC score : %s \"% roc_auc)\n",
        "\n",
        "# calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(Y_test, pred_test)\n",
        "# calculate precision-recall AUC\n",
        "prc_auc = auc(recall, precision)\n",
        "print(\"AUPRC score : %s \"% prc_auc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "masking_3 (Masking)          (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 64)                12672     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_3_ptbdb (Dense)        (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 21,057\n",
            "Trainable params: 21,057\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10476 samples, validate on 1165 samples\n",
            "Epoch 1/10\n",
            " - 39s - loss: 0.5594 - acc: 0.7236 - val_loss: 0.5324 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to gru_64_ptbdb.h5\n",
            "Epoch 2/10\n",
            " - 38s - loss: 0.5119 - acc: 0.7238 - val_loss: 0.5207 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.69957\n",
            "Epoch 3/10\n",
            " - 38s - loss: 0.5036 - acc: 0.7305 - val_loss: 0.5490 - val_acc: 0.6979\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.69957\n",
            "Epoch 4/10\n",
            " - 37s - loss: 0.4931 - acc: 0.7391 - val_loss: 0.5022 - val_acc: 0.7391\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.69957 to 0.73906, saving model to gru_64_ptbdb.h5\n",
            "Epoch 5/10\n",
            " - 38s - loss: 0.4752 - acc: 0.7444 - val_loss: 0.5060 - val_acc: 0.7451\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.73906 to 0.74506, saving model to gru_64_ptbdb.h5\n",
            "Epoch 6/10\n",
            " - 38s - loss: 0.4715 - acc: 0.7526 - val_loss: 0.4773 - val_acc: 0.7588\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.74506 to 0.75880, saving model to gru_64_ptbdb.h5\n",
            "Epoch 7/10\n",
            " - 38s - loss: 0.4652 - acc: 0.7571 - val_loss: 0.4861 - val_acc: 0.7588\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.75880\n",
            "Epoch 8/10\n",
            " - 38s - loss: 0.4592 - acc: 0.7590 - val_loss: 0.4838 - val_acc: 0.7562\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.75880\n",
            "Epoch 9/10\n",
            " - 38s - loss: 0.4508 - acc: 0.7671 - val_loss: 0.4862 - val_acc: 0.7674\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.75880 to 0.76738, saving model to gru_64_ptbdb.h5\n",
            "Epoch 10/10\n",
            " - 38s - loss: 0.4505 - acc: 0.7676 - val_loss: 0.4546 - val_acc: 0.7897\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.76738 to 0.78970, saving model to gru_64_ptbdb.h5\n",
            "GRU with 64 hidden layers model results\n",
            "Test f1 score : 0.8598298253470668 \n",
            "Test accuracy score : 0.7849536241841292 \n",
            "AUROC score : 0.6822950418637145 \n",
            "AUPRC score : 0.8940600029416614 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RV6SkclpiTOB",
        "colab_type": "code",
        "outputId": "00391fec-7ff9-4600-f0f7-ed19a8f7f33c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1190
        }
      },
      "cell_type": "code",
      "source": [
        "model = get_gru_model(n_hidden=128)\n",
        "file_path = \"gru_128_ptbdb.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
        "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint, early, redonplat]  # early\n",
        "\n",
        "model.fit(X, Y, epochs=n_epochs, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
        "model.load_weights(file_path)\n",
        "\n",
        "pred_test = model.predict(X_test)\n",
        "pred_test = (pred_test>0.5).astype(np.int8)\n",
        "\n",
        "print('GRU with 128 hidden layers model results')\n",
        "f1 = f1_score(Y_test, pred_test)\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "acc = accuracy_score(Y_test, pred_test)\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "\n",
        "# calculate Receiver Operating Characteristics AUC\n",
        "roc_auc = roc_auc_score(Y_test, pred_test)\n",
        "print(\"AUROC score : %s \"% roc_auc)\n",
        "\n",
        "# calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(Y_test, pred_test)\n",
        "# calculate precision-recall AUC\n",
        "prc_auc = auc(recall, precision)\n",
        "print(\"AUPRC score : %s \"% prc_auc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "masking_4 (Masking)          (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 128)               49920     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_3_ptbdb (Dense)        (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 62,401\n",
            "Trainable params: 62,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10476 samples, validate on 1165 samples\n",
            "Epoch 1/10\n",
            " - 105s - loss: 0.5863 - acc: 0.7232 - val_loss: 0.6078 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to gru_128_ptbdb.h5\n",
            "Epoch 2/10\n",
            " - 104s - loss: 0.5585 - acc: 0.7244 - val_loss: 0.5480 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.69957\n",
            "Epoch 3/10\n",
            " - 104s - loss: 0.5323 - acc: 0.7244 - val_loss: 0.5387 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.69957\n",
            "Epoch 4/10\n",
            " - 103s - loss: 0.5218 - acc: 0.7244 - val_loss: 0.5016 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.69957\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 5/10\n",
            " - 103s - loss: 0.4698 - acc: 0.7247 - val_loss: 0.4792 - val_acc: 0.7193\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.69957 to 0.71931, saving model to gru_128_ptbdb.h5\n",
            "Epoch 6/10\n",
            " - 104s - loss: 0.4530 - acc: 0.7443 - val_loss: 0.4669 - val_acc: 0.7459\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.71931 to 0.74592, saving model to gru_128_ptbdb.h5\n",
            "Epoch 7/10\n",
            " - 103s - loss: 0.4469 - acc: 0.7575 - val_loss: 0.4552 - val_acc: 0.7631\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.74592 to 0.76309, saving model to gru_128_ptbdb.h5\n",
            "Epoch 8/10\n",
            " - 103s - loss: 0.4298 - acc: 0.7774 - val_loss: 0.4387 - val_acc: 0.7631\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.76309\n",
            "Epoch 9/10\n",
            " - 103s - loss: 0.4123 - acc: 0.7955 - val_loss: 0.4126 - val_acc: 0.8043\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.76309 to 0.80429, saving model to gru_128_ptbdb.h5\n",
            "Epoch 10/10\n",
            " - 103s - loss: 0.3857 - acc: 0.8177 - val_loss: 0.3843 - val_acc: 0.8180\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.80429 to 0.81803, saving model to gru_128_ptbdb.h5\n",
            "GRU with 128 hidden layers model results\n",
            "Test f1 score : 0.8779769211883134 \n",
            "Test accuracy score : 0.8292682926829268 \n",
            "AUROC score : 0.8122066335081428 \n",
            "AUPRC score : 0.9328194500761628 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x4wtKmfWWMdY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### LSTM implementation"
      ]
    },
    {
      "metadata": {
        "id": "RDCbKAcml9TJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_lstm_model():\n",
        "    nclass = 1\n",
        "    inp = Input(shape=(187, 1))\n",
        "    mask_inp = Masking(mask_value=0.)(inp)\n",
        "    img_1 = LSTM(64)(mask_inp)\n",
        "    img_1 = Dropout(rate=0.2)(img_1)\n",
        "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
        "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
        "    dense_1 = Dense(nclass, activation=activations.sigmoid, name=\"dense_3_ptbdb\")(dense_1)\n",
        "\n",
        "    model = models.Model(inputs=inp, outputs=dense_1)\n",
        "    opt = optimizers.Adam(0.001)\n",
        "\n",
        "    model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['acc'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0afJu8KrPu8E",
        "colab_type": "code",
        "outputId": "79aa3b29-2403-4896-81aa-ce14521555b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1156
        }
      },
      "cell_type": "code",
      "source": [
        "model = get_lstm_model()\n",
        "file_path = \"lstm_64_ptbdb.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
        "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint, early, redonplat]  # early\n",
        "\n",
        "model.fit(X, Y, epochs=n_epochs, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
        "model.load_weights(file_path)\n",
        "\n",
        "pred_test = model.predict(X_test)\n",
        "pred_test = (pred_test>0.5).astype(np.int8)\n",
        "\n",
        "print('LSTM with 64 hidden layers model results')\n",
        "f1 = f1_score(Y_test, pred_test)\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "acc = accuracy_score(Y_test, pred_test)\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "\n",
        "# calculate Receiver Operating Characteristics AUC\n",
        "roc_auc = roc_auc_score(Y_test, pred_test)\n",
        "print(\"AUROC score : %s \"% roc_auc)\n",
        "\n",
        "# calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(Y_test, pred_test)\n",
        "# calculate precision-recall AUC\n",
        "prc_auc = auc(recall, precision)\n",
        "print(\"AUPRC score : %s \"% prc_auc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "masking_5 (Masking)          (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                16896     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_3_ptbdb (Dense)        (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 25,281\n",
            "Trainable params: 25,281\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10476 samples, validate on 1165 samples\n",
            "Epoch 1/10\n",
            " - 49s - loss: 0.5758 - acc: 0.7224 - val_loss: 0.6103 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to lstm_64_ptbdb.h5\n",
            "Epoch 2/10\n",
            " - 47s - loss: 0.5890 - acc: 0.7244 - val_loss: 0.6119 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.69957\n",
            "Epoch 3/10\n",
            " - 48s - loss: 0.5612 - acc: 0.7244 - val_loss: 0.5424 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.69957\n",
            "Epoch 4/10\n",
            " - 47s - loss: 0.5121 - acc: 0.7254 - val_loss: 0.5263 - val_acc: 0.7210\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.69957 to 0.72103, saving model to lstm_64_ptbdb.h5\n",
            "Epoch 5/10\n",
            " - 47s - loss: 0.5038 - acc: 0.7241 - val_loss: 0.5262 - val_acc: 0.7090\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.72103\n",
            "Epoch 6/10\n",
            " - 47s - loss: 0.4968 - acc: 0.7345 - val_loss: 0.5161 - val_acc: 0.7133\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.72103\n",
            "Epoch 7/10\n",
            " - 47s - loss: 0.4806 - acc: 0.7465 - val_loss: 0.4975 - val_acc: 0.7494\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.72103 to 0.74936, saving model to lstm_64_ptbdb.h5\n",
            "Epoch 8/10\n",
            " - 47s - loss: 0.4715 - acc: 0.7546 - val_loss: 0.4957 - val_acc: 0.7348\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.74936\n",
            "Epoch 9/10\n",
            " - 47s - loss: 0.4664 - acc: 0.7560 - val_loss: 0.4601 - val_acc: 0.7700\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.74936 to 0.76996, saving model to lstm_64_ptbdb.h5\n",
            "Epoch 10/10\n",
            " - 48s - loss: 0.4458 - acc: 0.7712 - val_loss: 0.4647 - val_acc: 0.7597\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.76996\n",
            "LSTM with 64 hidden layers model results\n",
            "Test f1 score : 0.8566857142857142 \n",
            "Test accuracy score : 0.784610099622123 \n",
            "AUROC score : 0.6991651955462981 \n",
            "AUPRC score : 0.8971582696074887 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gYSU9idGdf9x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Out of simple RNN, GRU and LSTM, GRU performs best and LSTM is closely behind while simple RNN is worse.\n",
        "We will therefore use GRU models in the future except if specified otherwise."
      ]
    },
    {
      "metadata": {
        "id": "t2m2LKPwWRqs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Bidirectional GRU implementation\n",
        "\n",
        "> Test Different merge methods for bidirectional model\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "q6lnyfYOJe7Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_bidirectional_gru_model(mode='sum', n_hidden=64, n_stacked_layers=1):\n",
        "    nclass = 1\n",
        "    inp = Input(shape=(187, 1))\n",
        "    gru_inp = Masking(mask_value=0.)(inp)\n",
        "    for n in range(n_stacked_layers):\n",
        "      return_seq = (n<n_stacked_layers-1)\n",
        "      gru_inp = Bidirectional(GRU(n_hidden, return_sequences=return_seq), merge_mode=mode)(gru_inp)\n",
        "      gru_inp = Dropout(rate=0.2)(gru_inp)\n",
        "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(gru_inp)\n",
        "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
        "    dense_1 = Dense(nclass, activation=activations.sigmoid, name=\"dense_3_ptbdb\")(dense_1)\n",
        "\n",
        "    model = models.Model(inputs=inp, outputs=dense_1)\n",
        "    opt = optimizers.Adam(0.001)\n",
        "\n",
        "    model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['acc'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iPtuxA6Yl_ee",
        "colab_type": "code",
        "outputId": "71605ed2-b776-44f4-d845-dfcd147afbc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4675
        }
      },
      "cell_type": "code",
      "source": [
        "for mode in ['sum', 'mul', 'concat', 'ave']:\n",
        "  print('Using mode: ', mode)\n",
        "  model = get_bidirectional_gru_model(mode)\n",
        "  file_path = \"bidirectional_gru_{}_ptbdb.h5\".format(mode)\n",
        "  checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "  early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
        "  redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
        "  callbacks_list = [checkpoint, early, redonplat]  # early\n",
        "\n",
        "  model.fit(X, Y, epochs=n_epochs, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
        "  model.load_weights(file_path)\n",
        "\n",
        "  pred_test = model.predict(X_test)\n",
        "  pred_test = (pred_test>0.5).astype(np.int8)\n",
        "  \n",
        "  print('Bidirectional({}) GRU with 64 hidden layers model results'.format(mode))\n",
        "  f1 = f1_score(Y_test, pred_test)\n",
        "  print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "  acc = accuracy_score(Y_test, pred_test)\n",
        "  print(\"Test accuracy score : %s \"% acc)\n",
        "  \n",
        "  # calculate Receiver Operating Characteristics AUC\n",
        "  roc_auc = roc_auc_score(Y_test, pred_test)\n",
        "  print(\"AUROC score : %s \"% roc_auc)\n",
        "\n",
        "  # calculate precision-recall curve\n",
        "  precision, recall, thresholds = precision_recall_curve(Y_test, pred_test)\n",
        "  # calculate precision-recall AUC\n",
        "  prc_auc = auc(recall, precision)\n",
        "  print(\"AUPRC score : %s \"% prc_auc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using mode:  sum\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "masking_6 (Masking)          (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 64)                25344     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_3_ptbdb (Dense)        (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 33,729\n",
            "Trainable params: 33,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10476 samples, validate on 1165 samples\n",
            "Epoch 1/10\n",
            " - 61s - loss: 0.5444 - acc: 0.7221 - val_loss: 0.5419 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to bidirectional_gru_sum_ptbdb.h5\n",
            "Epoch 2/10\n",
            " - 59s - loss: 0.5029 - acc: 0.7241 - val_loss: 0.5121 - val_acc: 0.7039\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.69957 to 0.70386, saving model to bidirectional_gru_sum_ptbdb.h5\n",
            "Epoch 3/10\n",
            " - 59s - loss: 0.4798 - acc: 0.7426 - val_loss: 0.4792 - val_acc: 0.7451\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.70386 to 0.74506, saving model to bidirectional_gru_sum_ptbdb.h5\n",
            "Epoch 4/10\n",
            " - 59s - loss: 0.4609 - acc: 0.7568 - val_loss: 0.4790 - val_acc: 0.7502\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.74506 to 0.75021, saving model to bidirectional_gru_sum_ptbdb.h5\n",
            "Epoch 5/10\n",
            " - 59s - loss: 0.4438 - acc: 0.7758 - val_loss: 0.4695 - val_acc: 0.7399\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.75021\n",
            "Epoch 6/10\n",
            " - 59s - loss: 0.4333 - acc: 0.7808 - val_loss: 0.4227 - val_acc: 0.7820\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.75021 to 0.78197, saving model to bidirectional_gru_sum_ptbdb.h5\n",
            "Epoch 7/10\n",
            " - 59s - loss: 0.4103 - acc: 0.7987 - val_loss: 0.4132 - val_acc: 0.7923\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.78197 to 0.79227, saving model to bidirectional_gru_sum_ptbdb.h5\n",
            "Epoch 8/10\n",
            " - 59s - loss: 0.3870 - acc: 0.8136 - val_loss: 0.3978 - val_acc: 0.8094\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.79227 to 0.80944, saving model to bidirectional_gru_sum_ptbdb.h5\n",
            "Epoch 9/10\n",
            " - 59s - loss: 0.3539 - acc: 0.8372 - val_loss: 0.3873 - val_acc: 0.8060\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80944\n",
            "Epoch 10/10\n",
            " - 59s - loss: 0.3285 - acc: 0.8496 - val_loss: 0.3199 - val_acc: 0.8609\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.80944 to 0.86094, saving model to bidirectional_gru_sum_ptbdb.h5\n",
            "Bidirectional(sum) GRU with 64 hidden layers model results\n",
            "Test f1 score : 0.9085768143261075 \n",
            "Test accuracy score : 0.8667124699416008 \n",
            "AUROC score : 0.8263487948966138 \n",
            "AUPRC score : 0.9385441690479004 \n",
            "Using mode:  mul\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "masking_7 (Masking)          (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 64)                25344     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_3_ptbdb (Dense)        (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 33,729\n",
            "Trainable params: 33,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10476 samples, validate on 1165 samples\n",
            "Epoch 1/10\n",
            " - 62s - loss: 0.5511 - acc: 0.7243 - val_loss: 0.5322 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to bidirectional_gru_mul_ptbdb.h5\n",
            "Epoch 2/10\n",
            " - 59s - loss: 0.5067 - acc: 0.7244 - val_loss: 0.5014 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.69957\n",
            "Epoch 3/10\n",
            " - 59s - loss: 0.4858 - acc: 0.7247 - val_loss: 0.4940 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.69957\n",
            "Epoch 4/10\n",
            " - 59s - loss: 0.4758 - acc: 0.7269 - val_loss: 0.4685 - val_acc: 0.7322\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.69957 to 0.73219, saving model to bidirectional_gru_mul_ptbdb.h5\n",
            "Epoch 5/10\n",
            " - 59s - loss: 0.4661 - acc: 0.7301 - val_loss: 0.5027 - val_acc: 0.7013\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.73219\n",
            "Epoch 6/10\n",
            " - 59s - loss: 0.4578 - acc: 0.7411 - val_loss: 0.4650 - val_acc: 0.7262\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.73219\n",
            "Epoch 7/10\n",
            " - 59s - loss: 0.4714 - acc: 0.7309 - val_loss: 0.4753 - val_acc: 0.7288\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.73219\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 8/10\n",
            " - 59s - loss: 0.4523 - acc: 0.7510 - val_loss: 0.4552 - val_acc: 0.7511\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.73219 to 0.75107, saving model to bidirectional_gru_mul_ptbdb.h5\n",
            "Epoch 9/10\n",
            " - 59s - loss: 0.4375 - acc: 0.7757 - val_loss: 0.4435 - val_acc: 0.7622\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.75107 to 0.76223, saving model to bidirectional_gru_mul_ptbdb.h5\n",
            "Epoch 10/10\n",
            " - 59s - loss: 0.4276 - acc: 0.7812 - val_loss: 0.4437 - val_acc: 0.7554\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.76223\n",
            "Bidirectional(mul) GRU with 64 hidden layers model results\n",
            "Test f1 score : 0.8570797437596643 \n",
            "Test accuracy score : 0.7777396083819993 \n",
            "AUROC score : 0.6617124899589419 \n",
            "AUPRC score : 0.8892907606928149 \n",
            "Using mode:  concat\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "masking_8 (Masking)          (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 128)               25344     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_3_ptbdb (Dense)        (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 37,825\n",
            "Trainable params: 37,825\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10476 samples, validate on 1165 samples\n",
            "Epoch 1/10\n",
            " - 63s - loss: 0.5459 - acc: 0.7242 - val_loss: 0.5412 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to bidirectional_gru_concat_ptbdb.h5\n",
            "Epoch 2/10\n",
            " - 59s - loss: 0.5012 - acc: 0.7301 - val_loss: 0.5024 - val_acc: 0.7253\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.69957 to 0.72532, saving model to bidirectional_gru_concat_ptbdb.h5\n",
            "Epoch 3/10\n",
            " - 60s - loss: 0.4661 - acc: 0.7548 - val_loss: 0.4326 - val_acc: 0.7974\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.72532 to 0.79742, saving model to bidirectional_gru_concat_ptbdb.h5\n",
            "Epoch 4/10\n",
            " - 60s - loss: 0.4283 - acc: 0.7856 - val_loss: 0.4056 - val_acc: 0.7923\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.79742\n",
            "Epoch 5/10\n",
            " - 60s - loss: 0.3967 - acc: 0.8044 - val_loss: 0.3954 - val_acc: 0.8172\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.79742 to 0.81717, saving model to bidirectional_gru_concat_ptbdb.h5\n",
            "Epoch 6/10\n",
            " - 60s - loss: 0.3696 - acc: 0.8200 - val_loss: 0.3912 - val_acc: 0.7974\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.81717\n",
            "Epoch 7/10\n",
            " - 59s - loss: 0.3468 - acc: 0.8337 - val_loss: 0.3188 - val_acc: 0.8472\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.81717 to 0.84721, saving model to bidirectional_gru_concat_ptbdb.h5\n",
            "Epoch 8/10\n",
            " - 59s - loss: 0.3182 - acc: 0.8517 - val_loss: 0.2864 - val_acc: 0.8661\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.84721 to 0.86609, saving model to bidirectional_gru_concat_ptbdb.h5\n",
            "Epoch 9/10\n",
            " - 59s - loss: 0.3097 - acc: 0.8585 - val_loss: 0.2776 - val_acc: 0.8833\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.86609 to 0.88326, saving model to bidirectional_gru_concat_ptbdb.h5\n",
            "Epoch 10/10\n",
            " - 59s - loss: 0.2728 - acc: 0.8781 - val_loss: 0.2584 - val_acc: 0.8936\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.88326 to 0.89356, saving model to bidirectional_gru_concat_ptbdb.h5\n",
            "Bidirectional(concat) GRU with 64 hidden layers model results\n",
            "Test f1 score : 0.923852990631756 \n",
            "Test accuracy score : 0.8911027138440398 \n",
            "AUROC score : 0.872131021253524 \n",
            "AUPRC score : 0.9546880578888126 \n",
            "Using mode:  ave\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "masking_9 (Masking)          (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 64)                25344     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_3_ptbdb (Dense)        (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 33,729\n",
            "Trainable params: 33,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10476 samples, validate on 1165 samples\n",
            "Epoch 1/10\n",
            " - 63s - loss: 0.5411 - acc: 0.7244 - val_loss: 0.5206 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to bidirectional_gru_ave_ptbdb.h5\n",
            "Epoch 2/10\n",
            " - 59s - loss: 0.4906 - acc: 0.7333 - val_loss: 0.4876 - val_acc: 0.7425\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.69957 to 0.74249, saving model to bidirectional_gru_ave_ptbdb.h5\n",
            "Epoch 3/10\n",
            " - 59s - loss: 0.4695 - acc: 0.7483 - val_loss: 0.4834 - val_acc: 0.7305\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.74249\n",
            "Epoch 4/10\n",
            " - 59s - loss: 0.4541 - acc: 0.7658 - val_loss: 0.4533 - val_acc: 0.7674\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.74249 to 0.76738, saving model to bidirectional_gru_ave_ptbdb.h5\n",
            "Epoch 5/10\n",
            " - 59s - loss: 0.4340 - acc: 0.7745 - val_loss: 0.5187 - val_acc: 0.7373\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.76738\n",
            "Epoch 6/10\n",
            " - 60s - loss: 0.4245 - acc: 0.7879 - val_loss: 0.3988 - val_acc: 0.8163\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.76738 to 0.81631, saving model to bidirectional_gru_ave_ptbdb.h5\n",
            "Epoch 7/10\n",
            " - 59s - loss: 0.3964 - acc: 0.8063 - val_loss: 0.4171 - val_acc: 0.7897\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.81631\n",
            "Epoch 8/10\n",
            " - 60s - loss: 0.3781 - acc: 0.8205 - val_loss: 0.3466 - val_acc: 0.8438\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.81631 to 0.84378, saving model to bidirectional_gru_ave_ptbdb.h5\n",
            "Epoch 9/10\n",
            " - 59s - loss: 0.3531 - acc: 0.8382 - val_loss: 0.3382 - val_acc: 0.8386\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.84378\n",
            "Epoch 10/10\n",
            " - 59s - loss: 0.3237 - acc: 0.8553 - val_loss: 0.3295 - val_acc: 0.8464\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.84378 to 0.84635, saving model to bidirectional_gru_ave_ptbdb.h5\n",
            "Bidirectional(ave) GRU with 64 hidden layers model results\n",
            "Test f1 score : 0.9086661994861014 \n",
            "Test accuracy score : 0.8656818962555822 \n",
            "AUROC score : 0.8180316233053693 \n",
            "AUPRC score : 0.9359269375613857 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "44biYLIvd5Ou",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Testing Bidirectional GRU model with different merge methods. \n",
        "- Concatenating and sum work well\n",
        "- Mul works well but generally not as good\n",
        "\n",
        "Use sum/concat in the future"
      ]
    },
    {
      "metadata": {
        "id": "PwJrXHHTWq49",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Stacking Bidirectional models\n",
        "\n",
        "> Test Drop out in every layer or only after first or last layer\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Tpo-pL8okGlt",
        "colab_type": "code",
        "outputId": "08631805-b182-4324-ec2d-7a8b6ee2fba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1207
        }
      },
      "cell_type": "code",
      "source": [
        "# Drop out after last layer\n",
        "def get_bidirectional_gru_model(mode='sum', n_hidden=64, n_stacked_layers=1):\n",
        "    nclass = 1\n",
        "    inp = Input(shape=(187, 1))\n",
        "    gru_inp = Masking(mask_value=0.)(inp)\n",
        "    for n in range(n_stacked_layers):\n",
        "      return_seq = (n<n_stacked_layers-1)\n",
        "      gru_inp = Bidirectional(GRU(n_hidden, return_sequences=return_seq), merge_mode=mode)(gru_inp)\n",
        "    gru_inp = Dropout(rate=0.2)(gru_inp)\n",
        "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(gru_inp)\n",
        "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
        "    dense_1 = Dense(nclass, activation=activations.sigmoid, name=\"dense_3_ptbdb\")(dense_1)\n",
        "\n",
        "    model = models.Model(inputs=inp, outputs=dense_1)\n",
        "    opt = optimizers.Adam(0.001)\n",
        "\n",
        "    model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['acc'])\n",
        "    model.summary()\n",
        "    return model\n",
        "  \n",
        "print('Using 2 stacked layers of GRU cells: ')\n",
        "model = get_bidirectional_gru_model('sum', 64, 2)\n",
        "file_path = \"bidirectional_gru_{}layers_{}hidden_dropoutlast_ptbdb.h5\".format(2, 64)\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
        "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint, early, redonplat]  # early\n",
        "\n",
        "model.fit(X, Y, epochs=n_epochs, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
        "model.load_weights(file_path)\n",
        "\n",
        "pred_test = model.predict(X_test)\n",
        "pred_test = (pred_test>0.5).astype(np.int8)\n",
        "\n",
        "print('{} layer stack of bidirectional GRU with dropout after last RNN layer model results'.format(2))\n",
        "f1 = f1_score(Y_test, pred_test)\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "acc = accuracy_score(Y_test, pred_test)\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "\n",
        "# calculate Receiver Operating Characteristics AUC\n",
        "roc_auc = roc_auc_score(Y_test, pred_test)\n",
        "print(\"AUROC score : %s \"% roc_auc)\n",
        "\n",
        "# calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(Y_test, pred_test)\n",
        "# calculate precision-recall AUC\n",
        "prc_auc = auc(recall, precision)\n",
        "print(\"AUPRC score : %s \"% prc_auc)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using 2 stacked layers of GRU cells: \n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "masking_9 (Masking)          (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_17 (Bidirectio (None, 187, 64)           25344     \n",
            "_________________________________________________________________\n",
            "bidirectional_18 (Bidirectio (None, 64)                49536     \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_3_ptbdb (Dense)        (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 83,265\n",
            "Trainable params: 83,265\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10476 samples, validate on 1165 samples\n",
            "Epoch 1/10\n",
            " - 152s - loss: 0.5256 - acc: 0.7227 - val_loss: 0.5128 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to bidirectional_gru_2layers_64hidden_dropoutlast_ptbdb.h5\n",
            "Epoch 2/10\n",
            " - 145s - loss: 0.4830 - acc: 0.7283 - val_loss: 0.4860 - val_acc: 0.7193\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.69957 to 0.71931, saving model to bidirectional_gru_2layers_64hidden_dropoutlast_ptbdb.h5\n",
            "Epoch 3/10\n",
            " - 144s - loss: 0.4523 - acc: 0.7599 - val_loss: 0.4446 - val_acc: 0.7734\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.71931 to 0.77339, saving model to bidirectional_gru_2layers_64hidden_dropoutlast_ptbdb.h5\n",
            "Epoch 4/10\n",
            " - 144s - loss: 0.4362 - acc: 0.7662 - val_loss: 0.4593 - val_acc: 0.7459\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.77339\n",
            "Epoch 5/10\n",
            " - 144s - loss: 0.4272 - acc: 0.7788 - val_loss: 0.3873 - val_acc: 0.8163\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.77339 to 0.81631, saving model to bidirectional_gru_2layers_64hidden_dropoutlast_ptbdb.h5\n",
            "Epoch 6/10\n",
            " - 144s - loss: 0.3134 - acc: 0.8649 - val_loss: 0.2642 - val_acc: 0.8970\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.81631 to 0.89700, saving model to bidirectional_gru_2layers_64hidden_dropoutlast_ptbdb.h5\n",
            "Epoch 7/10\n",
            " - 144s - loss: 0.2412 - acc: 0.9052 - val_loss: 0.2932 - val_acc: 0.8893\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.89700\n",
            "Epoch 8/10\n",
            " - 143s - loss: 0.2189 - acc: 0.9130 - val_loss: 0.2029 - val_acc: 0.9193\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.89700 to 0.91931, saving model to bidirectional_gru_2layers_64hidden_dropoutlast_ptbdb.h5\n",
            "Epoch 9/10\n",
            " - 144s - loss: 0.1822 - acc: 0.9311 - val_loss: 0.3357 - val_acc: 0.8704\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.91931\n",
            "Epoch 10/10\n",
            " - 143s - loss: 0.1619 - acc: 0.9389 - val_loss: 0.1497 - val_acc: 0.9468\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.91931 to 0.94678, saving model to bidirectional_gru_2layers_64hidden_dropoutlast_ptbdb.h5\n",
            "2 layer stack of bidirectional GRU with dropout after last RNN layer model results\n",
            "Test f1 score : 0.9640219204193472 \n",
            "Test accuracy score : 0.9481277911370662 \n",
            "AUROC score : 0.9367089910250876 \n",
            "AUPRC score : 0.9775938222943055 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bgRH8ghYlMbB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1207
        },
        "outputId": "26347fa0-9214-430b-e655-ee9ee2602b04"
      },
      "cell_type": "code",
      "source": [
        "# Drop out only after first layer\n",
        "def get_bidirectional_gru_model(mode='sum', n_hidden=64, n_stacked_layers=1):\n",
        "    nclass = 1\n",
        "    inp = Input(shape=(187, 1))\n",
        "    gru_inp = Masking(mask_value=0.)(inp)\n",
        "    for n in range(n_stacked_layers):\n",
        "      return_seq = (n<n_stacked_layers-1)\n",
        "      gru_inp = Bidirectional(GRU(n_hidden, return_sequences=return_seq), merge_mode=mode)(gru_inp)\n",
        "      if(n==0):\n",
        "        gru_inp = Dropout(rate=0.2)(gru_inp)\n",
        "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(gru_inp)\n",
        "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
        "    dense_1 = Dense(nclass, activation=activations.sigmoid, name=\"dense_3_ptbdb\")(dense_1)\n",
        "\n",
        "    model = models.Model(inputs=inp, outputs=dense_1)\n",
        "    opt = optimizers.Adam(0.001)\n",
        "\n",
        "    model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['acc'])\n",
        "    model.summary()\n",
        "    return model\n",
        "  \n",
        "print('Using 2 stacked layers of GRU cells: ')\n",
        "model = get_bidirectional_gru_model('sum', 64, 2)\n",
        "file_path = \"bidirectional_gru_{}layers_{}hidden_dropoutfirst_ptbdb.h5\".format(2, 64)\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
        "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint, early, redonplat]  # early\n",
        "\n",
        "model.fit(X, Y, epochs=n_epochs, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
        "model.load_weights(file_path)\n",
        "\n",
        "pred_test = model.predict(X_test)\n",
        "pred_test = (pred_test>0.5).astype(np.int8)\n",
        "\n",
        "print('{} layer stack of bidirectional GRU with dropout after first RNN layer model results'.format(2))\n",
        "f1 = f1_score(Y_test, pred_test)\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "acc = accuracy_score(Y_test, pred_test)\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "\n",
        "# calculate Receiver Operating Characteristics AUC\n",
        "roc_auc = roc_auc_score(Y_test, pred_test)\n",
        "print(\"AUROC score : %s \"% roc_auc)\n",
        "\n",
        "# calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(Y_test, pred_test)\n",
        "# calculate precision-recall AUC\n",
        "prc_auc = auc(recall, precision)\n",
        "print(\"AUPRC score : %s \"% prc_auc)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using 2 stacked layers of GRU cells: \n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "masking_10 (Masking)         (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_19 (Bidirectio (None, 187, 64)           25344     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 187, 64)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_20 (Bidirectio (None, 64)                49536     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_3_ptbdb (Dense)        (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 83,265\n",
            "Trainable params: 83,265\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10476 samples, validate on 1165 samples\n",
            "Epoch 1/10\n",
            " - 155s - loss: 0.5242 - acc: 0.7264 - val_loss: 0.5117 - val_acc: 0.7004\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.70043, saving model to bidirectional_gru_2layers_64hidden_dropoutfirst_ptbdb.h5\n",
            "Epoch 2/10\n",
            " - 146s - loss: 0.4887 - acc: 0.7342 - val_loss: 0.4966 - val_acc: 0.7073\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.70043 to 0.70730, saving model to bidirectional_gru_2layers_64hidden_dropoutfirst_ptbdb.h5\n",
            "Epoch 3/10\n",
            " - 146s - loss: 0.4569 - acc: 0.7517 - val_loss: 0.4609 - val_acc: 0.7476\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.70730 to 0.74764, saving model to bidirectional_gru_2layers_64hidden_dropoutfirst_ptbdb.h5\n",
            "Epoch 4/10\n",
            " - 146s - loss: 0.4964 - acc: 0.7285 - val_loss: 0.5015 - val_acc: 0.7004\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.74764\n",
            "Epoch 5/10\n",
            " - 147s - loss: 0.4796 - acc: 0.7297 - val_loss: 0.4815 - val_acc: 0.7571\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.74764 to 0.75708, saving model to bidirectional_gru_2layers_64hidden_dropoutfirst_ptbdb.h5\n",
            "Epoch 6/10\n",
            " - 145s - loss: 0.4680 - acc: 0.7501 - val_loss: 0.4227 - val_acc: 0.7966\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.75708 to 0.79657, saving model to bidirectional_gru_2layers_64hidden_dropoutfirst_ptbdb.h5\n",
            "Epoch 7/10\n",
            " - 146s - loss: 0.3965 - acc: 0.8119 - val_loss: 0.3562 - val_acc: 0.8343\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.79657 to 0.83433, saving model to bidirectional_gru_2layers_64hidden_dropoutfirst_ptbdb.h5\n",
            "Epoch 8/10\n",
            " - 145s - loss: 0.3329 - acc: 0.8495 - val_loss: 0.2944 - val_acc: 0.8730\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.83433 to 0.87296, saving model to bidirectional_gru_2layers_64hidden_dropoutfirst_ptbdb.h5\n",
            "Epoch 9/10\n",
            " - 146s - loss: 0.2702 - acc: 0.8897 - val_loss: 0.3133 - val_acc: 0.8592\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87296\n",
            "Epoch 10/10\n",
            " - 146s - loss: 0.2207 - acc: 0.9145 - val_loss: 0.2191 - val_acc: 0.9142\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.87296 to 0.91416, saving model to bidirectional_gru_2layers_64hidden_dropoutfirst_ptbdb.h5\n",
            "2 layer stack of bidirectional GRU with dropout after first RNN layer model results\n",
            "Test f1 score : 0.9419568822553896 \n",
            "Test accuracy score : 0.915836482308485 \n",
            "AUROC score : 0.8919188153256832 \n",
            "AUPRC score : 0.961553061651258 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q9R0lE-BmDMB",
        "colab_type": "code",
        "outputId": "c3d99741-a55c-4561-8991-dbe1c4d41243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2567
        }
      },
      "cell_type": "code",
      "source": [
        "hidden=64\n",
        "for stack_layers in [2,3]:\n",
        "  print('Using {} stacked layers of GRU cells: '.format(stack_layers))\n",
        "  model = get_bidirectional_gru_model('sum', hidden, stack_layers)\n",
        "  file_path = \"bidirectional_gru_{}layers_{}hidden_ptbdb.h5\".format(stack_layers, hidden)\n",
        "  checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "  early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
        "  redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
        "  callbacks_list = [checkpoint, early, redonplat]  # early\n",
        "\n",
        "  model.fit(X, Y, epochs=n_epochs, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
        "  model.load_weights(file_path)\n",
        "\n",
        "  pred_test = model.predict(X_test)\n",
        "  pred_test = (pred_test>0.5).astype(np.int8)\n",
        "\n",
        "  print('{} layer stack of bidirectional GRU model results'.format(stack_layers))\n",
        "  f1 = f1_score(Y_test, pred_test)\n",
        "  print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "  acc = accuracy_score(Y_test, pred_test)\n",
        "  print(\"Test accuracy score : %s \"% acc)\n",
        "  \n",
        "  # calculate Receiver Operating Characteristics AUC\n",
        "  roc_auc = roc_auc_score(Y_test, pred_test)\n",
        "  print(\"AUROC score : %s \"% roc_auc)\n",
        "\n",
        "  # calculate precision-recall curve\n",
        "  precision, recall, thresholds = precision_recall_curve(Y_test, pred_test)\n",
        "  # calculate precision-recall AUC\n",
        "  prc_auc = auc(recall, precision)\n",
        "  print(\"AUPRC score : %s \"% prc_auc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using 2 stacked layers of GRU cells: \n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_44 (InputLayer)        (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "masking_35 (Masking)         (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_36 (Bidirectio (None, 187, 128)          25344     \n",
            "_________________________________________________________________\n",
            "dropout_57 (Dropout)         (None, 187, 128)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_37 (Bidirectio (None, 128)               74112     \n",
            "_________________________________________________________________\n",
            "dropout_58 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_3_ptbdb (Dense)        (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 111,937\n",
            "Trainable params: 111,937\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10476 samples, validate on 1165 samples\n",
            "Epoch 1/10\n",
            " - 173s - loss: 0.5252 - acc: 0.7253 - val_loss: 0.5205 - val_acc: 0.7227\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.72275, saving model to bidirectional_gru_2layers_ptbdb.h5\n",
            "Epoch 2/10\n",
            " - 161s - loss: 0.4805 - acc: 0.7330 - val_loss: 0.4529 - val_acc: 0.7691\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.72275 to 0.76910, saving model to bidirectional_gru_2layers_ptbdb.h5\n",
            "Epoch 3/10\n",
            " - 161s - loss: 0.4364 - acc: 0.7701 - val_loss: 0.4488 - val_acc: 0.7820\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.76910 to 0.78197, saving model to bidirectional_gru_2layers_ptbdb.h5\n",
            "Epoch 4/10\n",
            " - 159s - loss: 0.4042 - acc: 0.8019 - val_loss: 0.3764 - val_acc: 0.8361\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.78197 to 0.83605, saving model to bidirectional_gru_2layers_ptbdb.h5\n",
            "Epoch 5/10\n",
            " - 163s - loss: 0.3495 - acc: 0.8420 - val_loss: 0.3379 - val_acc: 0.8498\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.83605 to 0.84979, saving model to bidirectional_gru_2layers_ptbdb.h5\n",
            "Epoch 6/10\n",
            " - 162s - loss: 0.2954 - acc: 0.8725 - val_loss: 0.2860 - val_acc: 0.8747\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.84979 to 0.87468, saving model to bidirectional_gru_2layers_ptbdb.h5\n",
            "Epoch 7/10\n",
            " - 161s - loss: 0.2646 - acc: 0.8876 - val_loss: 0.4283 - val_acc: 0.7691\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87468\n",
            "Epoch 8/10\n",
            " - 162s - loss: 0.3704 - acc: 0.8188 - val_loss: 0.3179 - val_acc: 0.8558\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.87468\n",
            "Epoch 9/10\n",
            " - 162s - loss: 0.2757 - acc: 0.8842 - val_loss: 0.3224 - val_acc: 0.8609\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.87468\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 10/10\n",
            " - 162s - loss: 0.2406 - acc: 0.9057 - val_loss: 0.2404 - val_acc: 0.9013\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.87468 to 0.90129, saving model to bidirectional_gru_2layers_ptbdb.h5\n",
            "ave layer stack of bidirectional GRU model results\n",
            "Test f1 score : 0.9378127233738385 \n",
            "Test accuracy score : 0.9103400893163861 \n",
            "AUROC score : 0.8896336292823717 \n",
            "AUPRC score : 0.9608314777963225 \n",
            "Using 3 stacked layers of GRU cells: \n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_45 (InputLayer)        (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "masking_36 (Masking)         (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_38 (Bidirectio (None, 187, 128)          25344     \n",
            "_________________________________________________________________\n",
            "dropout_59 (Dropout)         (None, 187, 128)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_39 (Bidirectio (None, 187, 128)          74112     \n",
            "_________________________________________________________________\n",
            "dropout_60 (Dropout)         (None, 187, 128)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_40 (Bidirectio (None, 128)               74112     \n",
            "_________________________________________________________________\n",
            "dropout_61 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_3_ptbdb (Dense)        (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 186,049\n",
            "Trainable params: 186,049\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10476 samples, validate on 1165 samples\n",
            "Epoch 1/10\n",
            " - 273s - loss: 0.5288 - acc: 0.7243 - val_loss: 0.5284 - val_acc: 0.7021\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.70215, saving model to bidirectional_gru_3layers_ptbdb.h5\n",
            "Epoch 2/10\n",
            " - 254s - loss: 0.4664 - acc: 0.7491 - val_loss: 0.4567 - val_acc: 0.7717\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.70215 to 0.77167, saving model to bidirectional_gru_3layers_ptbdb.h5\n",
            "Epoch 3/10\n",
            " - 265s - loss: 0.4269 - acc: 0.7864 - val_loss: 0.4148 - val_acc: 0.8077\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.77167 to 0.80773, saving model to bidirectional_gru_3layers_ptbdb.h5\n",
            "Epoch 4/10\n",
            " - 267s - loss: 0.3928 - acc: 0.8056 - val_loss: 0.3869 - val_acc: 0.8060\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80773\n",
            "Epoch 5/10\n",
            " - 268s - loss: 0.3534 - acc: 0.8361 - val_loss: 0.3369 - val_acc: 0.8446\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.80773 to 0.84464, saving model to bidirectional_gru_3layers_ptbdb.h5\n",
            "Epoch 6/10\n",
            " - 267s - loss: 0.3063 - acc: 0.8673 - val_loss: 0.2613 - val_acc: 0.8961\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.84464 to 0.89614, saving model to bidirectional_gru_3layers_ptbdb.h5\n",
            "Epoch 7/10\n",
            " - 267s - loss: 0.2702 - acc: 0.8852 - val_loss: 0.3411 - val_acc: 0.8652\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.89614\n",
            "Epoch 8/10\n",
            " - 265s - loss: 0.2157 - acc: 0.9099 - val_loss: 0.2224 - val_acc: 0.9047\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.89614 to 0.90472, saving model to bidirectional_gru_3layers_ptbdb.h5\n",
            "Epoch 9/10\n",
            " - 267s - loss: 0.1904 - acc: 0.9247 - val_loss: 0.1805 - val_acc: 0.9279\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.90472 to 0.92790, saving model to bidirectional_gru_3layers_ptbdb.h5\n",
            "Epoch 10/10\n",
            " - 267s - loss: 0.1591 - acc: 0.9391 - val_loss: 0.1776 - val_acc: 0.9236\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.92790\n",
            "ave layer stack of bidirectional GRU model results\n",
            "Test f1 score : 0.9519650655021834 \n",
            "Test accuracy score : 0.9319821367227756 \n",
            "AUROC score : 0.9308516581418131 \n",
            "AUPRC score : 0.9763886661897324 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-5AV60TtfaUe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The bigger the stack the better the performance. With a stack of three we already get a 93% accuracy and 97.6% AUPRC. However with a bigger stack the more time it takes to learn each model and computation becomes considerably more expensive:"
      ]
    },
    {
      "metadata": {
        "id": "v5c-qEBeueDO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Ensemble\n"
      ]
    },
    {
      "metadata": {
        "id": "IlFu0IR2geTA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Models to use for ensemble"
      ]
    },
    {
      "metadata": {
        "id": "lxc9ec8OmRKI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Gather all results in dictionary."
      ]
    },
    {
      "metadata": {
        "id": "wu2mk0gHmY4o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "result_dict = dict()\n",
        "# Add baseline results\n",
        "result_dict['CNN baseline'] = baseline_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tAOI7p1QW5dz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 1. Bidirectional GRU; hidden size=128, stack layers=1, merge method=sum\n",
        "\n",
        "\n",
        "> Learn a wide model with big hidden size of GRU\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "rkN7fAuzjq3t",
        "colab_type": "code",
        "outputId": "485ec3c9-1622-403a-d322-343a1ecdbcf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1156
        }
      },
      "cell_type": "code",
      "source": [
        "model_big_hidden = get_bidirectional_gru_model(mode='sum', n_hidden=128, n_stacked_layers=1)\n",
        "\n",
        "file_path = \"bi_gru_128_1stacklayer_ptbdb.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
        "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint, early, redonplat]  # early\n",
        "\n",
        "model_big_hidden.fit(X, Y, epochs=n_epochs, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
        "model_big_hidden.load_weights(file_path)\n",
        "\n",
        "pred_test = model_big_hidden.predict(X_test)\n",
        "pred_test = (pred_test>0.5).astype(np.int8)\n",
        "\n",
        "print('1 Layer of Bidirectional GRU with 128 hidden layers model results')\n",
        "f1 = f1_score(Y_test, pred_test)\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "acc = accuracy_score(Y_test, pred_test)\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "\n",
        "# calculate Receiver Operating Characteristics AUC\n",
        "roc_auc = roc_auc_score(Y_test, pred_test)\n",
        "print(\"AUROC score : %s \"% roc_auc)\n",
        "\n",
        "# calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(Y_test, pred_test)\n",
        "# calculate precision-recall AUC\n",
        "prc_auc = auc(recall, precision)\n",
        "print(\"AUPRC score : %s \"% prc_auc)\n",
        "\n",
        "result_dict['Bid. GRU Hidden State Size=128'] = [f1, acc, roc_auc, prc_auc]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "masking_4 (Masking)          (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 128)               99840     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_3_ptbdb (Dense)        (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 112,321\n",
            "Trainable params: 112,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10476 samples, validate on 1165 samples\n",
            "Epoch 1/10\n",
            " - 157s - loss: 0.5394 - acc: 0.7225 - val_loss: 0.5292 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to bi_gru_128_1stacklayer_ptbdb.h5\n",
            "Epoch 2/10\n",
            " - 153s - loss: 0.4994 - acc: 0.7308 - val_loss: 0.5031 - val_acc: 0.7124\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.69957 to 0.71245, saving model to bi_gru_128_1stacklayer_ptbdb.h5\n",
            "Epoch 3/10\n",
            " - 153s - loss: 0.4790 - acc: 0.7429 - val_loss: 0.4987 - val_acc: 0.7519\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.71245 to 0.75193, saving model to bi_gru_128_1stacklayer_ptbdb.h5\n",
            "Epoch 4/10\n",
            " - 153s - loss: 0.4654 - acc: 0.7556 - val_loss: 0.4687 - val_acc: 0.7416\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.75193\n",
            "Epoch 5/10\n",
            " - 153s - loss: 0.4465 - acc: 0.7732 - val_loss: 0.4501 - val_acc: 0.7588\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.75193 to 0.75880, saving model to bi_gru_128_1stacklayer_ptbdb.h5\n",
            "Epoch 6/10\n",
            " - 153s - loss: 0.4156 - acc: 0.7910 - val_loss: 0.4188 - val_acc: 0.7948\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.75880 to 0.79485, saving model to bi_gru_128_1stacklayer_ptbdb.h5\n",
            "Epoch 7/10\n",
            " - 154s - loss: 0.3815 - acc: 0.8103 - val_loss: 0.4049 - val_acc: 0.7983\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.79485 to 0.79828, saving model to bi_gru_128_1stacklayer_ptbdb.h5\n",
            "Epoch 8/10\n",
            " - 153s - loss: 0.3684 - acc: 0.8194 - val_loss: 0.3898 - val_acc: 0.8172\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.79828 to 0.81717, saving model to bi_gru_128_1stacklayer_ptbdb.h5\n",
            "Epoch 9/10\n",
            " - 153s - loss: 0.3505 - acc: 0.8388 - val_loss: 0.4067 - val_acc: 0.7983\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.81717\n",
            "Epoch 10/10\n",
            " - 153s - loss: 0.3104 - acc: 0.8636 - val_loss: 0.2937 - val_acc: 0.8721\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.81717 to 0.87210, saving model to bi_gru_128_1stacklayer_ptbdb.h5\n",
            "1 Layer of Bidirectional GRU with 128 hidden layers model results\n",
            "Test f1 score : 0.9193470955352857 \n",
            "Test accuracy score : 0.8845757471659224 \n",
            "AUROC score : 0.8634295549944192 \n",
            "AUPRC score : 0.9515431390655934 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-wcY6G9UXQTY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 2. Bidirectional GRU; hidden size=64, stack layers=2, merge method=sum\n",
        "\n",
        "> Learn deeper model which isn't too expensive to learn\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "sC3B7qD2k0As",
        "colab_type": "code",
        "outputId": "71af8d3e-f1d1-44c6-995b-3ec184ddc501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1190
        }
      },
      "cell_type": "code",
      "source": [
        "model_2layerstack = get_bidirectional_gru_model(mode='sum', n_hidden=64, n_stacked_layers=2)\n",
        "\n",
        "file_path = \"bi_gru_64_2stacklayer_ptbdb.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
        "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint, early, redonplat]  # early\n",
        "\n",
        "model_2layerstack.fit(X, Y, epochs=n_epochs, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
        "model_2layerstack.load_weights(file_path)\n",
        "\n",
        "pred_test = model_2layerstack.predict(X_test)\n",
        "pred_test = (pred_test>0.5).astype(np.int8)\n",
        "\n",
        "print('2 Layer of Bidirectional GRU with 64 hidden layers model results')\n",
        "f1 = f1_score(Y_test, pred_test)\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "acc = accuracy_score(Y_test, pred_test)\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "\n",
        "# calculate Receiver Operating Characteristics AUC\n",
        "roc_auc = roc_auc_score(Y_test, pred_test)\n",
        "print(\"AUROC score : %s \"% roc_auc)\n",
        "\n",
        "# calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(Y_test, pred_test)\n",
        "# calculate precision-recall AUC\n",
        "prc_auc = auc(recall, precision)\n",
        "print(\"AUPRC score : %s \"% prc_auc)\n",
        "\n",
        "result_dict['2 Stacked Bid. GRU Hidden State Size=64'] = [f1, acc, roc_auc, prc_auc]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "masking_11 (Masking)         (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_21 (Bidirectio (None, 187, 64)           25344     \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 187, 64)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_22 (Bidirectio (None, 64)                49536     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_3_ptbdb (Dense)        (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 83,265\n",
            "Trainable params: 83,265\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10476 samples, validate on 1165 samples\n",
            "Epoch 1/10\n",
            " - 155s - loss: 0.5225 - acc: 0.7253 - val_loss: 0.5025 - val_acc: 0.7056\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.70558, saving model to bi_gru_64_2stacklayer_ptbdb.h5\n",
            "Epoch 2/10\n",
            " - 146s - loss: 0.4688 - acc: 0.7517 - val_loss: 0.5227 - val_acc: 0.7322\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.70558 to 0.73219, saving model to bi_gru_64_2stacklayer_ptbdb.h5\n",
            "Epoch 3/10\n",
            " - 147s - loss: 0.3966 - acc: 0.8032 - val_loss: 0.3615 - val_acc: 0.8197\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.73219 to 0.81974, saving model to bi_gru_64_2stacklayer_ptbdb.h5\n",
            "Epoch 4/10\n",
            " - 146s - loss: 0.3191 - acc: 0.8515 - val_loss: 0.3103 - val_acc: 0.8601\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.81974 to 0.86009, saving model to bi_gru_64_2stacklayer_ptbdb.h5\n",
            "Epoch 5/10\n",
            " - 146s - loss: 0.2822 - acc: 0.8731 - val_loss: 0.2863 - val_acc: 0.8635\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.86009 to 0.86352, saving model to bi_gru_64_2stacklayer_ptbdb.h5\n",
            "Epoch 6/10\n",
            " - 146s - loss: 0.2346 - acc: 0.9042 - val_loss: 0.3776 - val_acc: 0.8137\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.86352\n",
            "Epoch 7/10\n",
            " - 146s - loss: 0.1953 - acc: 0.9228 - val_loss: 0.2200 - val_acc: 0.9021\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.86352 to 0.90215, saving model to bi_gru_64_2stacklayer_ptbdb.h5\n",
            "Epoch 8/10\n",
            " - 146s - loss: 0.1627 - acc: 0.9359 - val_loss: 0.2887 - val_acc: 0.8927\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.90215\n",
            "Epoch 9/10\n",
            " - 147s - loss: 0.1524 - acc: 0.9402 - val_loss: 0.1311 - val_acc: 0.9433\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.90215 to 0.94335, saving model to bi_gru_64_2stacklayer_ptbdb.h5\n",
            "Epoch 10/10\n",
            " - 147s - loss: 0.1343 - acc: 0.9494 - val_loss: 0.1363 - val_acc: 0.9502\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.94335 to 0.95021, saving model to bi_gru_64_2stacklayer_ptbdb.h5\n",
            "2 Layer of Bidirectional GRU with 64 hidden layers model results\n",
            "Test f1 score : 0.9655667144906743 \n",
            "Test accuracy score : 0.9505324630711096 \n",
            "AUROC score : 0.9425560329264377 \n",
            "AUPRC score : 0.979849705976993 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hjaUKm0KYCqv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 3. Bidirectional GRU; hidden size=64, stack layers=3, merge method=sum\n",
        "\n",
        "> Learn deep model with 3 layers. Is a lot more expensive to learn so mostly not used in ensemble models\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "HBXcFmgglxBT",
        "colab_type": "code",
        "outputId": "ca9b706a-f707-47b6-8b80-3fd822854a3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1292
        }
      },
      "cell_type": "code",
      "source": [
        "model_3layerstack = get_bidirectional_gru_model(mode='sum', n_hidden=64, n_stacked_layers=3)\n",
        "\n",
        "file_path = \"bi_gru_64_3stacklayer_ptbdb.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
        "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint, early, redonplat]  # early\n",
        "\n",
        "model_3layerstack.fit(X, Y, epochs=n_epochs, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
        "model_3layerstack.load_weights(file_path)\n",
        "\n",
        "pred_test = model_3layerstack.predict(X_test)\n",
        "pred_test = (pred_test>0.5).astype(np.int8)\n",
        "\n",
        "print('3 Layer of Bidirectional GRU with 64 hidden layers model results')\n",
        "f1 = f1_score(Y_test, pred_test)\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "acc = accuracy_score(Y_test, pred_test)\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "\n",
        "# calculate Receiver Operating Characteristics AUC\n",
        "roc_auc = roc_auc_score(Y_test, pred_test)\n",
        "print(\"AUROC score : %s \"% roc_auc)\n",
        "\n",
        "# calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(Y_test, pred_test)\n",
        "# calculate precision-recall AUC\n",
        "prc_auc = auc(recall, precision)\n",
        "print(\"AUPRC score : %s \"% prc_auc)\n",
        "\n",
        "result_dict['3 Stacked Bid. GRU Hidden State Size=64'] = [f1, acc, roc_auc, prc_auc]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "masking_7 (Masking)          (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_12 (Bidirectio (None, 187, 64)           25344     \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 187, 64)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_13 (Bidirectio (None, 187, 64)           49536     \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 187, 64)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_14 (Bidirectio (None, 64)                49536     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_3_ptbdb (Dense)        (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 132,801\n",
            "Trainable params: 132,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10476 samples, validate on 1165 samples\n",
            "Epoch 1/10\n",
            " - 240s - loss: 0.5233 - acc: 0.7233 - val_loss: 0.5257 - val_acc: 0.6970\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.69700, saving model to bi_gru_64_3stacklayer_ptbdb.h5\n",
            "Epoch 2/10\n",
            " - 232s - loss: 0.4768 - acc: 0.7257 - val_loss: 0.5061 - val_acc: 0.7133\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.69700 to 0.71330, saving model to bi_gru_64_3stacklayer_ptbdb.h5\n",
            "Epoch 3/10\n",
            " - 232s - loss: 0.4380 - acc: 0.7697 - val_loss: 0.4224 - val_acc: 0.7931\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.71330 to 0.79313, saving model to bi_gru_64_3stacklayer_ptbdb.h5\n",
            "Epoch 4/10\n",
            " - 233s - loss: 0.4009 - acc: 0.7999 - val_loss: 0.3992 - val_acc: 0.7914\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.79313\n",
            "Epoch 5/10\n",
            " - 233s - loss: 0.3525 - acc: 0.8363 - val_loss: 0.3267 - val_acc: 0.8532\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.79313 to 0.85322, saving model to bi_gru_64_3stacklayer_ptbdb.h5\n",
            "Epoch 6/10\n",
            " - 233s - loss: 0.3052 - acc: 0.8675 - val_loss: 0.2891 - val_acc: 0.8755\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.85322 to 0.87554, saving model to bi_gru_64_3stacklayer_ptbdb.h5\n",
            "Epoch 7/10\n",
            " - 231s - loss: 0.2412 - acc: 0.9002 - val_loss: 0.2952 - val_acc: 0.8755\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87554\n",
            "Epoch 8/10\n",
            " - 231s - loss: 0.2122 - acc: 0.9177 - val_loss: 0.2108 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.87554 to 0.91588, saving model to bi_gru_64_3stacklayer_ptbdb.h5\n",
            "Epoch 9/10\n",
            " - 232s - loss: 0.1865 - acc: 0.9233 - val_loss: 0.2115 - val_acc: 0.9159\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.91588\n",
            "Epoch 10/10\n",
            " - 233s - loss: 0.1586 - acc: 0.9401 - val_loss: 0.1590 - val_acc: 0.9442\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.91588 to 0.94421, saving model to bi_gru_64_3stacklayer_ptbdb.h5\n",
            "3 Layer of Bidirectional GRU with 64 hidden layers model results\n",
            "Test f1 score : 0.9617281051890114 \n",
            "Test accuracy score : 0.9440054963929921 \n",
            "AUROC score : 0.9197879704889923 \n",
            "AUPRC score : 0.9711636796189772 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wTbkfJi2YMqG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 4. Bidirectional LSTM; hidden size=64, stack layers=1, concat=sum, mode=sum\n",
        "\n",
        "> Learn Bidirectional LSTM model that might learn better long term dependecies in comparison to other ensemble models\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "3UC07UnMW2zR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_bidirectional_lstm_model(mode='sum', n_hidden=64, n_stacked_layers=1):\n",
        "    nclass = 1\n",
        "    inp = Input(shape=(187, 1))\n",
        "    rnn_inp = Masking(mask_value=0.)(inp)\n",
        "    for n in range(n_stacked_layers):\n",
        "      return_seq = (n<n_stacked_layers-1)\n",
        "      rnn_inp = Bidirectional(LSTM(n_hidden, return_sequences=return_seq), merge_mode=mode)(rnn_inp)\n",
        "      rnn_inp = Dropout(rate=0.2)(rnn_inp)\n",
        "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(rnn_inp)\n",
        "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
        "    dense_1 = Dense(nclass, activation=activations.sigmoid, name=\"dense_3_ptbdb\")(dense_1)\n",
        "\n",
        "    model = models.Model(inputs=inp, outputs=dense_1)\n",
        "    opt = optimizers.Adam(0.001)\n",
        "\n",
        "    model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['acc'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xjubBHNKXNCi",
        "colab_type": "code",
        "outputId": "086b2253-9fd0-4f5f-d424-097292f00a3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1156
        }
      },
      "cell_type": "code",
      "source": [
        "model_lstm = get_bidirectional_lstm_model(mode='sum', n_hidden=64, n_stacked_layers=1)\n",
        "\n",
        "file_path = \"biadd_lstm_64hidden_1stacklayer_ptbdb.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
        "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint, early, redonplat]  # early\n",
        "\n",
        "model_lstm.fit(X, Y, epochs=n_epochs, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
        "model_lstm.load_weights(file_path)\n",
        "\n",
        "pred_test = model_lstm.predict(X_test)\n",
        "pred_test = (pred_test>0.5).astype(np.int8)\n",
        "\n",
        "print('1 Layer of Bidirectional(add) LSTM with 64 hidden layers model results')\n",
        "f1 = f1_score(Y_test, pred_test)\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "acc = accuracy_score(Y_test, pred_test)\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "\n",
        "# calculate Receiver Operating Characteristics AUC\n",
        "roc_auc = roc_auc_score(Y_test, pred_test)\n",
        "print(\"AUROC score : %s \"% roc_auc)\n",
        "\n",
        "# calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(Y_test, pred_test)\n",
        "# calculate precision-recall AUC\n",
        "prc_auc = auc(recall, precision)\n",
        "print(\"AUPRC score : %s \"% prc_auc)\n",
        "\n",
        "result_dict['Bid. LSTM Hidden state size=64'] = [f1, acc, roc_auc, prc_auc]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "masking_3 (Masking)          (None, 187, 1)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 64)                33792     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_3_ptbdb (Dense)        (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 42,177\n",
            "Trainable params: 42,177\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10476 samples, validate on 1165 samples\n",
            "Epoch 1/10\n",
            " - 91s - loss: 0.5648 - acc: 0.7245 - val_loss: 0.5765 - val_acc: 0.6996\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.69957, saving model to biadd_lstm_64hidden_1stacklayer_ptbdb.h5\n",
            "Epoch 2/10\n",
            " - 88s - loss: 0.4653 - acc: 0.7459 - val_loss: 0.4270 - val_acc: 0.7803\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.69957 to 0.78026, saving model to biadd_lstm_64hidden_1stacklayer_ptbdb.h5\n",
            "Epoch 3/10\n",
            " - 88s - loss: 0.4086 - acc: 0.7868 - val_loss: 0.3879 - val_acc: 0.8086\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.78026 to 0.80858, saving model to biadd_lstm_64hidden_1stacklayer_ptbdb.h5\n",
            "Epoch 4/10\n",
            " - 87s - loss: 0.3940 - acc: 0.8046 - val_loss: 0.3749 - val_acc: 0.8103\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.80858 to 0.81030, saving model to biadd_lstm_64hidden_1stacklayer_ptbdb.h5\n",
            "Epoch 5/10\n",
            " - 88s - loss: 0.3752 - acc: 0.8129 - val_loss: 0.3684 - val_acc: 0.8146\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.81030 to 0.81459, saving model to biadd_lstm_64hidden_1stacklayer_ptbdb.h5\n",
            "Epoch 6/10\n",
            " - 87s - loss: 0.3633 - acc: 0.8195 - val_loss: 0.3466 - val_acc: 0.8189\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.81459 to 0.81888, saving model to biadd_lstm_64hidden_1stacklayer_ptbdb.h5\n",
            "Epoch 7/10\n",
            " - 87s - loss: 0.3571 - acc: 0.8261 - val_loss: 0.3395 - val_acc: 0.8361\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.81888 to 0.83605, saving model to biadd_lstm_64hidden_1stacklayer_ptbdb.h5\n",
            "Epoch 8/10\n",
            " - 88s - loss: 0.3435 - acc: 0.8352 - val_loss: 0.3345 - val_acc: 0.8498\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.83605 to 0.84979, saving model to biadd_lstm_64hidden_1stacklayer_ptbdb.h5\n",
            "Epoch 9/10\n",
            " - 88s - loss: 0.3302 - acc: 0.8445 - val_loss: 0.3083 - val_acc: 0.8627\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.84979 to 0.86266, saving model to biadd_lstm_64hidden_1stacklayer_ptbdb.h5\n",
            "Epoch 10/10\n",
            " - 87s - loss: 0.3140 - acc: 0.8578 - val_loss: 0.3129 - val_acc: 0.8567\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.86266\n",
            "1 Layer of Bidirectional(add) LSTM with 64 hidden layers model results\n",
            "Test f1 score : 0.9073079617090826 \n",
            "Test accuracy score : 0.8636207488835451 \n",
            "AUROC score : 0.8150836980261308 \n",
            "AUPRC score : 0.9349269524747783 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F66tYvyRG_o9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Ensemble by averaging predictions\n",
        "\n",
        "\n",
        ">Weights chosen by performance (0.3 2layer, 0.3 3layer, 0.2 big hidden, 0.2 lstm)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "NyMhLjd5Fn6v",
        "colab_type": "code",
        "outputId": "5f7b5730-3bbb-4e26-ab9e-de739bb59acd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "pred_test_model2layerstack = model_2layerstack.predict(X_test)\n",
        "pred_test_model3layerstack = model_3layerstack.predict(X_test)\n",
        "pred_test_model_bighidden = model_big_hidden.predict(X_test)\n",
        "pred_test_model_lstm = model_lstm.predict(X_test)\n",
        "\n",
        "pred_test_ensemble = np.array([pred_test_model2layerstack, pred_test_model3layerstack, pred_test_model_bighidden, pred_test_model_lstm])\n",
        "pred_test = np.average(pred_test_ensemble, weights=[0.3,0.3,0.2, 0.2], axis=0)\n",
        "pred_test = (pred_test>0.5).astype(np.int8)\n",
        "\n",
        "print('Ensemble Model by averaging')\n",
        "f1 = f1_score(Y_test, pred_test)\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "acc = accuracy_score(Y_test, pred_test)\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "\n",
        "# calculate Receiver Operating Characteristics AUC\n",
        "roc_auc = roc_auc_score(Y_test, pred_test)\n",
        "print(\"AUROC score : %s \"% roc_auc)\n",
        "\n",
        "# calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(Y_test, pred_test)\n",
        "# calculate precision-recall AUC\n",
        "prc_auc = auc(recall, precision)\n",
        "print(\"AUPRC score : %s \"% prc_auc)\n",
        "\n",
        "result_dict['Ensemble by Averaging models'] = [f1, acc, roc_auc, prc_auc]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ensemble Model by averaging\n",
            "Test f1 score : 0.9700259617654 \n",
            "Test accuracy score : 0.9563723806252147 \n",
            "AUROC score : 0.9393764135398743 \n",
            "AUPRC score : 0.9781576354749486 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eW5X0EHZ0Lx3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Ensemble model with logistic regression\n",
        "\n",
        "> Should at least improve or equal to averaging ensemble but doens't learn und doesn't learn throughout epochs.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Pq51WKkL1Cej",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Validation set\n",
        "X_val = X[int(len(X)*0.9):]\n",
        "Y_val = Y[int(len(Y)*0.9):]\n",
        "pred_val = []\n",
        "pred_test = []\n",
        "\n",
        "ensemble_models = [model_big_hidden, model_2layerstack, model_3layerstack, model_lstm]\n",
        "for i in range(len(ensemble_models)):\n",
        "  pred_val.append(ensemble_models[i].predict(X_val))\n",
        "  pred_test.append(ensemble_models[i].predict(X_test))\n",
        "pred_val_ensemble = np.concatenate (tuple(pred_val), axis=1)\n",
        "pred_test_ensemble = np.concatenate (tuple(pred_test), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "swHcjJifvLSg",
        "colab_type": "code",
        "outputId": "6f8d6a6c-6842-4efa-c701-1ef8a879cc54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "ensemble_lr = LogisticRegression(C=100)\n",
        "ensemble_lr.fit(pred_val_ensemble, Y_val)\n",
        "\n",
        "pred_test = ensemble_lr.predict(pred_test_ensemble)\n",
        "pred_test = (pred_test>0.5).astype(np.int8)\n",
        "\n",
        "print('Ensemble Model with logistic regression')\n",
        "f1 = f1_score(Y_test, pred_test)\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "acc = accuracy_score(Y_test, pred_test)\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "\n",
        "# calculate Receiver Operating Characteristics AUC\n",
        "roc_auc = roc_auc_score(Y_test, pred_test)\n",
        "print(\"AUROC score : %s \"% roc_auc)\n",
        "\n",
        "# calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(Y_test, pred_test)\n",
        "# calculate precision-recall AUC\n",
        "prc_auc = auc(recall, precision)\n",
        "print(\"AUPRC score : %s \"% prc_auc)\n",
        "\n",
        "result_dict['Ensemble by fitting a Logistic Regression Model'] = [f1, acc, roc_auc, prc_auc]"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ensemble Model with logistic regression\n",
            "Test f1 score : 0.973178257773558 \n",
            "Test accuracy score : 0.9611817244933013 \n",
            "AUROC score : 0.9499299625173034 \n",
            "AUPRC score : 0.9821143375463377 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "aJkf2MYsBYGi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Results"
      ]
    },
    {
      "metadata": {
        "id": "hCP2st-Vr_4M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "948e95a1-2c6f-4be5-f291-6b44f8b53b4b"
      },
      "cell_type": "code",
      "source": [
        "Results1 = pd.DataFrame.from_dict(result_dict, orient='index',columns=['Test F1 score', 'Test Accuracy', 'Test AUROC', 'Test AUPRC'])\n",
        "Results1"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test F1 score</th>\n",
              "      <th>Test Accuracy</th>\n",
              "      <th>Test AUROC</th>\n",
              "      <th>Test AUPRC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Ensemble by Averaging models</th>\n",
              "      <td>0.970026</td>\n",
              "      <td>0.956372</td>\n",
              "      <td>0.939376</td>\n",
              "      <td>0.978158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ensemble by fitting a Logistic Regression Model</th>\n",
              "      <td>0.973178</td>\n",
              "      <td>0.961182</td>\n",
              "      <td>0.949930</td>\n",
              "      <td>0.982114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bid. GRU Hidden State Size=128</th>\n",
              "      <td>0.965567</td>\n",
              "      <td>0.950532</td>\n",
              "      <td>0.942556</td>\n",
              "      <td>0.979850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2 Stacked Bid. GRU Hidden State Size=64</th>\n",
              "      <td>0.961728</td>\n",
              "      <td>0.944005</td>\n",
              "      <td>0.919788</td>\n",
              "      <td>0.971164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3 Stacked Bid. GRU Hidden State Size=64</th>\n",
              "      <td>0.919347</td>\n",
              "      <td>0.884576</td>\n",
              "      <td>0.863430</td>\n",
              "      <td>0.951543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bid. LSTM Hidden state size=64</th>\n",
              "      <td>0.907308</td>\n",
              "      <td>0.863621</td>\n",
              "      <td>0.815084</td>\n",
              "      <td>0.934927</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Test F1 score  Test Accuracy  \\\n",
              "Ensemble by Averaging models                          0.970026       0.956372   \n",
              "Ensemble by fitting a Logistic Regression Model       0.973178       0.961182   \n",
              "Bid. GRU Hidden State Size=128                        0.965567       0.950532   \n",
              "2 Stacked Bid. GRU Hidden State Size=64               0.961728       0.944005   \n",
              "3 Stacked Bid. GRU Hidden State Size=64               0.919347       0.884576   \n",
              "Bid. LSTM Hidden state size=64                        0.907308       0.863621   \n",
              "\n",
              "                                                 Test AUROC  Test AUPRC  \n",
              "Ensemble by Averaging models                       0.939376    0.978158  \n",
              "Ensemble by fitting a Logistic Regression Model    0.949930    0.982114  \n",
              "Bid. GRU Hidden State Size=128                     0.942556    0.979850  \n",
              "2 Stacked Bid. GRU Hidden State Size=64            0.919788    0.971164  \n",
              "3 Stacked Bid. GRU Hidden State Size=64            0.863430    0.951543  \n",
              "Bid. LSTM Hidden state size=64                     0.815084    0.934927  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "metadata": {
        "id": "B58MoVcEBVST",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}